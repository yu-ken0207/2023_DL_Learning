{"cells":[{"cell_type":"markdown","metadata":{"id":"qbdTlqPUta32"},"source":["# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"]},{"cell_type":"markdown","metadata":{"id":"lMgQisATta3_"},"source":["Before we start, please put your name and SID in following format: <br>\n",": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"]},{"cell_type":"markdown","metadata":{"id":"p1VfE1w8ta4A"},"source":["**Your Answer:**    \n","Hi I'm 游凱翔, M124020034."]},{"cell_type":"markdown","metadata":{"id":"IWMWW8Ab_345"},"source":["## Google Colab Setup\n","Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n","\n","Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vH4wc4iD_6w_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699595007764,"user_tz":-480,"elapsed":17782,"user":{"displayName":"游凱翔","userId":"00765381750409268011"}},"outputId":"766785e4-46d1-427d-e651-10f0499c2972"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Um5DJvBwb6xT"},"source":["# Data Setup (5 points)\n","\n","The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n","\n","Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHkeNUOKiFbP"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import random\n","\n","\n","def rotate_img(img, rot):\n","    if rot == 0: # 0 degrees rotation\n","        return img\n","    elif rot == 1: # 90 degrees rotation\n","        return torch.rot90(img, 1, (1, 2))\n","    elif rot == 2: # 180 degrees rotation\n","        return torch.rot90(img, 2, (1, 2))\n","    elif rot == 3: # 270 degrees rotation\n","        return torch.rot90(img, 3, (1, 2))\n","    else:\n","        raise ValueError('rotation should be 0, 1, 2, or 3 degrees')\n","\n","class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n","\n","    def __init__(self, root, train, download, transform) -> None:\n","        super().__init__(root=root, train=train, download=download, transform=transform)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index: int):\n","        image, cls_label = super().__getitem__(index)\n","\n","        # randomly select image rotation\n","        rotation_label = random.choice([0, 1, 2, 3])\n","        image_rotated = rotate_img(image, rotation_label)\n","\n","        rotation_label = torch.tensor(rotation_label).long()\n","        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCBSpNWpb8uw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699624692984,"user_tz":-480,"elapsed":15323,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"0698b26f-b103-401a-d04f-54d1320d7017"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:10<00:00, 16519210.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","batch_size = 128\n","trainset = CIFAR10Rotation(root='./data', train=True,download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=2)\n","\n","testset = CIFAR10Rotation(root='./data', train=False,download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"dOCWMyGhVOJB"},"source":["Show some example images and rotated images with labels:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9wN4BJWVMzB","colab":{"base_uri":"https://localhost:8080/","height":432},"executionInfo":{"status":"ok","timestamp":1699624693978,"user_tz":-480,"elapsed":998,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"c25da66d-232d-41fb-b5de-d0b132b77561"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["Class labels:  car   cat   cat   bird \n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Rotation labels:  180   90    180   90   \n"]}],"source":["import matplotlib.pyplot as plt\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","rot_classes = ('0', '90', '180', '270')\n","\n","\n","def imshow(img):\n","    # unnormalize\n","    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n","    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","dataiter = iter(trainloader)\n","images, rot_images, rot_labels, labels = next(dataiter)\n","\n","# print images and rotated images\n","img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n","print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n","img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n","print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"unCucbHexG4W"},"source":["# Evaluation code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pptQRpqK0rOl"},"outputs":[],"source":["import time\n","\n","def run_test(net, testloader, criterion, task):\n","    correct = 0\n","    total = 0\n","    avg_test_loss = 0.0\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for images, images_rotated, labels, cls_labels in testloader:\n","            if task == 'rotation':\n","              images, labels = images_rotated.to(device), labels.to(device)\n","            elif task == 'classification':\n","              images, labels = images.to(device), cls_labels.to(device)\n","            #######################################################################\n","            # TODO: Calculate outputs by running images through the network       #\n","            # The class with the highest energy is what we choose as prediction   #\n","            #######################################################################\n","            outputs = net(images.to(device))\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            #######################################################################\n","            #                           End of your code                          #\n","            #######################################################################\n","            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n","    print('TESTING:')\n","    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n","    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hf698c16A9k5"},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n","    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"]},{"cell_type":"markdown","metadata":{"id":"3lYdnb1Wsta_"},"source":["# Train a ResNet18 on the rotation task (9 points)\n","\n","In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knAiwdURvBHk","outputId":"92921a8c-23d9-4f53-e20d-c23a8715e325","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699624698249,"user_tz":-480,"elapsed":2,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":7}],"source":["# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# device\n","device = torch.device('cuda')\n","device"]},{"cell_type":"markdown","metadata":{"id":"wOmsZddyta4P"},"source":["### 1  Notice: You should not use pretrained weights from ImageNet. 77.15 %"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"235MEIUgsv65","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699624704444,"user_tz":-480,"elapsed":871,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"f5ab35b6-52c4-41a8-9150-960ac07a75dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=4, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","net = resnet18(weights = None, num_classes=4) # Do not modify this line.\n","net = net.to(device)\n","print(net) # print your model and check the num_classes is correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vuhiw0ZoszAd"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","################################################################################\n","# TODO: Define loss and optmizer functions                                     #\n","# Try any loss or optimizer function and learning rate to get better result    #\n","# hint: torch.nn and torch.optim                                               #\n","################################################################################\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","################################################################################\n","#                               End of your code                               #\n","################################################################################\n","criterion = criterion.to(device)"]},{"cell_type":"code","source":["# Both the self-supervised rotation task and supervised CIFAR10 classification are\n","# trained with the CrossEntropyLoss, so we can use the training loop code.\n","\n","def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n","    for epoch in range(num_epochs):  # loop over the dataset multiple times\n","        running_loss = 0.0\n","        running_correct = 0.0\n","        running_total = 0.0\n","        start_time = time.time()\n","        net = net.to(device)\n","        net.train()\n","        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n","            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n","            ######################################################################################################\n","            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #\n","            # TODO: Zero the parameter gradients                                                                 #\n","            # TODO: forward + backward + optimize                                                                #\n","            # TODO: Get predicted results                                                                        #\n","            ######################################################################################################\n","            imgs = imgs.to(device)\n","            imgs_rotated = imgs_rotated.to(device)\n","            rotation_label = rotation_label.to(device)\n","            cls_label = cls_label.to(device)\n","\n","            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n","            if task == 'rotation':\n","                inputs, labels = imgs_rotated, rotation_label\n","            elif task == 'classification':\n","                inputs, labels = imgs, cls_label\n","            optimizer.zero_grad()  # zero the parameter gradients\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Get predicted results\n","            _, predicted = torch.max(outputs, 1)\n","            ######################################################################################################\n","            #                               End of your code                                                     #\n","            ######################################################################################################\n","            # print statistics\n","            print_freq = 100\n","            running_loss += loss.item()\n","            # calc acc\n","            running_total += labels.size(0)\n","            running_correct += (predicted == labels).sum().item()\n","\n","            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n","                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n","                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n","                start_time = time.time()\n","        ######################################################################################################\n","        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n","        ######################################################################################################\n","        run_test(net, testloader, criterion, task)  # Call your test function here\n","        net.eval()\n","        ######################################################################################################\n","        #                               End of your code                                                     #\n","        ######################################################################################################\n","    print('Finished Training')"],"metadata":{"id":"AYpH8tyNyzDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2u4AsfAKtaQS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699613454312,"user_tz":-480,"elapsed":1440081,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"b13e3847-9e67-43c3-f98c-5105c3533e40"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 1.582 acc: 28.39 time: 6.34\n","[1,   200] loss: 1.303 acc: 43.48 time: 7.42\n","[1,   300] loss: 1.190 acc: 48.09 time: 6.12\n","TESTING:\n","Accuracy of the network on the 10000 test images: 52.55 %\n","Average loss on the 10000 test images: 1.119\n","[2,   100] loss: 1.126 acc: 50.78 time: 10.97\n","[2,   200] loss: 1.109 acc: 52.09 time: 10.79\n","[2,   300] loss: 1.091 acc: 52.59 time: 9.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 55.84 %\n","Average loss on the 10000 test images: 1.047\n","[3,   100] loss: 1.052 acc: 55.77 time: 8.13\n","[3,   200] loss: 1.031 acc: 55.84 time: 6.65\n","[3,   300] loss: 1.046 acc: 55.59 time: 7.91\n","TESTING:\n","Accuracy of the network on the 10000 test images: 59.20 %\n","Average loss on the 10000 test images: 0.974\n","[4,   100] loss: 0.999 acc: 57.84 time: 7.14\n","[4,   200] loss: 0.982 acc: 58.64 time: 8.08\n","[4,   300] loss: 0.961 acc: 59.38 time: 7.48\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.25 %\n","Average loss on the 10000 test images: 0.937\n","[5,   100] loss: 0.944 acc: 60.98 time: 8.44\n","[5,   200] loss: 0.944 acc: 60.34 time: 7.66\n","[5,   300] loss: 0.927 acc: 61.47 time: 7.90\n","TESTING:\n","Accuracy of the network on the 10000 test images: 62.09 %\n","Average loss on the 10000 test images: 0.904\n","[6,   100] loss: 0.921 acc: 61.37 time: 7.61\n","[6,   200] loss: 0.901 acc: 62.28 time: 7.34\n","[6,   300] loss: 0.893 acc: 63.20 time: 8.10\n","TESTING:\n","Accuracy of the network on the 10000 test images: 63.86 %\n","Average loss on the 10000 test images: 0.882\n","[7,   100] loss: 0.879 acc: 63.77 time: 8.63\n","[7,   200] loss: 0.892 acc: 63.20 time: 7.92\n","[7,   300] loss: 0.879 acc: 63.14 time: 10.76\n","TESTING:\n","Accuracy of the network on the 10000 test images: 65.07 %\n","Average loss on the 10000 test images: 0.853\n","[8,   100] loss: 0.866 acc: 63.91 time: 7.82\n","[8,   200] loss: 0.848 acc: 65.02 time: 6.58\n","[8,   300] loss: 0.850 acc: 64.88 time: 8.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 64.40 %\n","Average loss on the 10000 test images: 0.854\n","[9,   100] loss: 0.851 acc: 64.72 time: 6.52\n","[9,   200] loss: 0.827 acc: 66.02 time: 7.86\n","[9,   300] loss: 0.835 acc: 65.66 time: 6.94\n","TESTING:\n","Accuracy of the network on the 10000 test images: 66.38 %\n","Average loss on the 10000 test images: 0.825\n","[10,   100] loss: 0.828 acc: 65.91 time: 7.51\n","[10,   200] loss: 0.822 acc: 65.77 time: 7.15\n","[10,   300] loss: 0.810 acc: 66.64 time: 7.54\n","TESTING:\n","Accuracy of the network on the 10000 test images: 66.73 %\n","Average loss on the 10000 test images: 0.811\n","[11,   100] loss: 0.823 acc: 66.57 time: 6.88\n","[11,   200] loss: 0.792 acc: 67.96 time: 7.86\n","[11,   300] loss: 0.784 acc: 68.09 time: 6.18\n","TESTING:\n","Accuracy of the network on the 10000 test images: 68.79 %\n","Average loss on the 10000 test images: 0.780\n","[12,   100] loss: 0.785 acc: 68.49 time: 8.10\n","[12,   200] loss: 0.793 acc: 67.68 time: 6.30\n","[12,   300] loss: 0.780 acc: 67.91 time: 7.43\n","TESTING:\n","Accuracy of the network on the 10000 test images: 69.86 %\n","Average loss on the 10000 test images: 0.749\n","[13,   100] loss: 0.766 acc: 68.72 time: 6.92\n","[13,   200] loss: 0.765 acc: 69.20 time: 8.11\n","[13,   300] loss: 0.756 acc: 69.46 time: 6.80\n","TESTING:\n","Accuracy of the network on the 10000 test images: 70.46 %\n","Average loss on the 10000 test images: 0.737\n","[14,   100] loss: 0.749 acc: 69.80 time: 8.31\n","[14,   200] loss: 0.750 acc: 69.98 time: 6.97\n","[14,   300] loss: 0.736 acc: 70.42 time: 7.47\n","TESTING:\n","Accuracy of the network on the 10000 test images: 69.72 %\n","Average loss on the 10000 test images: 0.758\n","[15,   100] loss: 0.739 acc: 70.59 time: 6.86\n","[15,   200] loss: 0.743 acc: 69.99 time: 9.23\n","[15,   300] loss: 0.728 acc: 70.98 time: 6.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 71.21 %\n","Average loss on the 10000 test images: 0.718\n","[16,   100] loss: 0.698 acc: 72.02 time: 7.62\n","[16,   200] loss: 0.669 acc: 73.44 time: 6.48\n","[16,   300] loss: 0.653 acc: 73.91 time: 7.79\n","TESTING:\n","Accuracy of the network on the 10000 test images: 74.18 %\n","Average loss on the 10000 test images: 0.663\n","[17,   100] loss: 0.650 acc: 74.12 time: 7.90\n","[17,   200] loss: 0.646 acc: 74.53 time: 6.74\n","[17,   300] loss: 0.636 acc: 74.84 time: 7.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 74.69 %\n","Average loss on the 10000 test images: 0.650\n","[18,   100] loss: 0.636 acc: 75.10 time: 6.60\n","[18,   200] loss: 0.634 acc: 74.95 time: 7.35\n","[18,   300] loss: 0.638 acc: 74.98 time: 6.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 74.78 %\n","Average loss on the 10000 test images: 0.640\n","[19,   100] loss: 0.624 acc: 75.23 time: 7.75\n","[19,   200] loss: 0.634 acc: 75.11 time: 6.38\n","[19,   300] loss: 0.632 acc: 75.21 time: 7.51\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.14 %\n","Average loss on the 10000 test images: 0.638\n","[20,   100] loss: 0.615 acc: 75.57 time: 6.51\n","[20,   200] loss: 0.621 acc: 75.77 time: 7.42\n","[20,   300] loss: 0.613 acc: 75.90 time: 6.18\n","TESTING:\n","Accuracy of the network on the 10000 test images: 74.87 %\n","Average loss on the 10000 test images: 0.631\n","[21,   100] loss: 0.606 acc: 76.18 time: 6.46\n","[21,   200] loss: 0.628 acc: 74.89 time: 7.21\n","[21,   300] loss: 0.616 acc: 75.65 time: 6.55\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.20 %\n","Average loss on the 10000 test images: 0.632\n","[22,   100] loss: 0.614 acc: 75.94 time: 7.55\n","[22,   200] loss: 0.620 acc: 75.55 time: 6.06\n","[22,   300] loss: 0.610 acc: 75.94 time: 7.45\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.02 %\n","Average loss on the 10000 test images: 0.611\n","[23,   100] loss: 0.604 acc: 76.18 time: 6.46\n","[23,   200] loss: 0.610 acc: 76.45 time: 8.80\n","[23,   300] loss: 0.593 acc: 77.12 time: 6.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.29 %\n","Average loss on the 10000 test images: 0.616\n","[24,   100] loss: 0.584 acc: 76.91 time: 7.78\n","[24,   200] loss: 0.592 acc: 76.79 time: 6.35\n","[24,   300] loss: 0.610 acc: 76.06 time: 7.25\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.12 %\n","Average loss on the 10000 test images: 0.613\n","[25,   100] loss: 0.580 acc: 77.59 time: 7.50\n","[25,   200] loss: 0.606 acc: 76.50 time: 6.64\n","[25,   300] loss: 0.593 acc: 77.11 time: 7.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.28 %\n","Average loss on the 10000 test images: 0.604\n","[26,   100] loss: 0.599 acc: 76.44 time: 6.25\n","[26,   200] loss: 0.582 acc: 77.05 time: 7.21\n","[26,   300] loss: 0.582 acc: 77.45 time: 6.42\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.34 %\n","Average loss on the 10000 test images: 0.606\n","[27,   100] loss: 0.591 acc: 77.08 time: 7.84\n","[27,   200] loss: 0.575 acc: 77.28 time: 6.20\n","[27,   300] loss: 0.582 acc: 76.67 time: 7.85\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.45 %\n","Average loss on the 10000 test images: 0.603\n","[28,   100] loss: 0.575 acc: 77.41 time: 6.34\n","[28,   200] loss: 0.570 acc: 77.67 time: 7.62\n","[28,   300] loss: 0.582 acc: 77.05 time: 6.76\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.66 %\n","Average loss on the 10000 test images: 0.594\n","[29,   100] loss: 0.580 acc: 77.38 time: 7.92\n","[29,   200] loss: 0.567 acc: 77.73 time: 6.64\n","[29,   300] loss: 0.578 acc: 77.38 time: 8.00\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.29 %\n","Average loss on the 10000 test images: 0.598\n","[30,   100] loss: 0.573 acc: 77.64 time: 7.14\n","[30,   200] loss: 0.572 acc: 77.55 time: 7.64\n","[30,   300] loss: 0.571 acc: 77.51 time: 6.75\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.78 %\n","Average loss on the 10000 test images: 0.594\n","[31,   100] loss: 0.571 acc: 77.74 time: 6.91\n","[31,   200] loss: 0.560 acc: 77.71 time: 7.79\n","[31,   300] loss: 0.562 acc: 78.39 time: 5.99\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.01 %\n","Average loss on the 10000 test images: 0.593\n","[32,   100] loss: 0.561 acc: 78.30 time: 7.39\n","[32,   200] loss: 0.565 acc: 77.88 time: 6.02\n","[32,   300] loss: 0.563 acc: 77.87 time: 7.22\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.26 %\n","Average loss on the 10000 test images: 0.584\n","[33,   100] loss: 0.573 acc: 77.59 time: 7.02\n","[33,   200] loss: 0.565 acc: 78.34 time: 8.33\n","[33,   300] loss: 0.562 acc: 77.91 time: 6.62\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.64 %\n","Average loss on the 10000 test images: 0.578\n","[34,   100] loss: 0.557 acc: 78.46 time: 6.18\n","[34,   200] loss: 0.554 acc: 78.38 time: 7.07\n","[34,   300] loss: 0.556 acc: 78.24 time: 6.04\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.09 %\n","Average loss on the 10000 test images: 0.585\n","[35,   100] loss: 0.563 acc: 78.03 time: 7.30\n","[35,   200] loss: 0.559 acc: 77.74 time: 5.88\n","[35,   300] loss: 0.560 acc: 78.06 time: 6.98\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.26 %\n","Average loss on the 10000 test images: 0.584\n","[36,   100] loss: 0.557 acc: 78.29 time: 8.15\n","[36,   200] loss: 0.555 acc: 78.36 time: 7.28\n","[36,   300] loss: 0.555 acc: 78.49 time: 6.77\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.07 %\n","Average loss on the 10000 test images: 0.585\n","[37,   100] loss: 0.568 acc: 77.56 time: 6.23\n","[37,   200] loss: 0.548 acc: 78.65 time: 8.26\n","[37,   300] loss: 0.554 acc: 78.49 time: 6.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.69 %\n","Average loss on the 10000 test images: 0.573\n","[38,   100] loss: 0.564 acc: 78.03 time: 7.35\n","[38,   200] loss: 0.552 acc: 78.40 time: 6.61\n","[38,   300] loss: 0.555 acc: 78.30 time: 7.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.56 %\n","Average loss on the 10000 test images: 0.576\n","[39,   100] loss: 0.549 acc: 78.48 time: 7.04\n","[39,   200] loss: 0.558 acc: 78.15 time: 8.58\n","[39,   300] loss: 0.556 acc: 78.37 time: 6.40\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.06 %\n","Average loss on the 10000 test images: 0.585\n","[40,   100] loss: 0.537 acc: 79.14 time: 6.50\n","[40,   200] loss: 0.564 acc: 77.73 time: 7.55\n","[40,   300] loss: 0.567 acc: 77.61 time: 6.49\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.35 %\n","Average loss on the 10000 test images: 0.580\n","[41,   100] loss: 0.552 acc: 78.60 time: 8.14\n","[41,   200] loss: 0.543 acc: 78.84 time: 6.39\n","[41,   300] loss: 0.560 acc: 77.99 time: 7.91\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.96 %\n","Average loss on the 10000 test images: 0.569\n","[42,   100] loss: 0.554 acc: 78.34 time: 7.96\n","[42,   200] loss: 0.552 acc: 78.10 time: 8.68\n","[42,   300] loss: 0.547 acc: 78.58 time: 8.00\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.31 %\n","Average loss on the 10000 test images: 0.580\n","[43,   100] loss: 0.554 acc: 78.35 time: 7.65\n","[43,   200] loss: 0.553 acc: 78.48 time: 6.18\n","[43,   300] loss: 0.549 acc: 78.62 time: 7.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.70 %\n","Average loss on the 10000 test images: 0.572\n","[44,   100] loss: 0.543 acc: 78.89 time: 6.13\n","[44,   200] loss: 0.559 acc: 78.07 time: 7.15\n","[44,   300] loss: 0.548 acc: 78.70 time: 5.92\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.05 %\n","Average loss on the 10000 test images: 0.583\n","[45,   100] loss: 0.541 acc: 78.80 time: 6.87\n","[45,   200] loss: 0.557 acc: 78.25 time: 6.55\n","[45,   300] loss: 0.562 acc: 77.92 time: 8.45\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.15 %\n","Average loss on the 10000 test images: 0.578\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.01, task='rotation')\n","################################\n","#     TODO: Save the model     #\n","################################\n","torch.save(net.state_dict(), 'rotation_model.pt')\n","\n","################################\n","#      End of your code        #\n","################################"]},{"cell_type":"markdown","metadata":{"id":"PLLMRTS9rTnk"},"source":["## 2-1  Fine-tuning on the pre-trained model (9 points) 58.19 % 保留L4 FC曾  10類\n","\n","In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n","\n","**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4nX4ExlrymI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699625808402,"user_tz":-480,"elapsed":320,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"8b71abf0-0b02-4b06-e385-f0aca72f4eb5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Original Model:\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=4, bias=True)\n",")\n","\n","Modified Model:\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","#####################################################\n","#     TODO: Load the pre-trained ResNet18 model     #\n","#####################################################\n","\n","# Load the pre-trained ResNet18 model\n","net = resnet18(pretrained=False,num_classes=4)\n","\n","# 載入模型權重\n","net.load_state_dict(torch.load('rotation_model.pt', map_location='cpu'))\n","\n","# 印修改前的模型\n","print(\"Original Model:\")\n","print(net)\n","\n","# 原始的fc層修改\n","fc_layers = [nn.Linear(512, 10)]\n","\n","# 新fc層替換原始fc\n","net.fc = nn.Sequential(*fc_layers)\n","\n","# 印修改後的模型\n","print(\"\\nModified Model:\")\n","print(net) # print your model and check the num_classes is correct\n","\n","####################################################\n","#                End of your code                  #\n","####################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kD44g-TxwYdU"},"outputs":[],"source":["#################################################################################################\n","#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n","#################################################################################################\n","# Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable\n","for name, param in net.named_parameters():\n","    if \"layer4\" in name or \"fc\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","#################################################################################################\n","#                                          End of your code                                     #\n","#################################################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9T5DX0efr4fh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699625813485,"user_tz":-480,"elapsed":2,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"083c21b8-1fb2-4645-b701-228193d9e44a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Params to learn:\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t fc.0.weight\n","\t fc.0.bias\n"]}],"source":["# Print all the trainable parameters\n","params_to_update = net.parameters()\n","print(\"Params to learn:\")\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb032dG700ph"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","# Note that your optimizer only needs to update the parameters that are trainable.\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params_to_update, lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vLSwOo6sBjl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699626356162,"user_tz":-480,"elapsed":539584,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"0fca9b35-0a2c-45bc-a1b7-8ecf742ba00a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 1.837 acc: 32.21 time: 5.58\n","[1,   200] loss: 1.563 acc: 42.41 time: 7.19\n","[1,   300] loss: 1.500 acc: 44.83 time: 5.78\n","TESTING:\n","Accuracy of the network on the 10000 test images: 47.82 %\n","Average loss on the 10000 test images: 1.434\n","[2,   100] loss: 1.422 acc: 48.15 time: 6.41\n","[2,   200] loss: 1.375 acc: 50.03 time: 8.00\n","[2,   300] loss: 1.407 acc: 49.25 time: 6.43\n","TESTING:\n","Accuracy of the network on the 10000 test images: 50.95 %\n","Average loss on the 10000 test images: 1.356\n","[3,   100] loss: 1.370 acc: 50.27 time: 6.76\n","[3,   200] loss: 1.368 acc: 50.02 time: 5.45\n","[3,   300] loss: 1.331 acc: 51.33 time: 7.00\n","TESTING:\n","Accuracy of the network on the 10000 test images: 51.87 %\n","Average loss on the 10000 test images: 1.338\n","[4,   100] loss: 1.315 acc: 52.85 time: 6.68\n","[4,   200] loss: 1.311 acc: 52.72 time: 5.51\n","[4,   300] loss: 1.319 acc: 52.71 time: 6.58\n","TESTING:\n","Accuracy of the network on the 10000 test images: 52.44 %\n","Average loss on the 10000 test images: 1.308\n","[5,   100] loss: 1.292 acc: 53.52 time: 6.33\n","[5,   200] loss: 1.304 acc: 53.28 time: 5.37\n","[5,   300] loss: 1.287 acc: 52.51 time: 6.64\n","TESTING:\n","Accuracy of the network on the 10000 test images: 54.34 %\n","Average loss on the 10000 test images: 1.274\n","[6,   100] loss: 1.270 acc: 53.58 time: 6.45\n","[6,   200] loss: 1.281 acc: 53.98 time: 5.92\n","[6,   300] loss: 1.270 acc: 53.77 time: 6.12\n","TESTING:\n","Accuracy of the network on the 10000 test images: 54.15 %\n","Average loss on the 10000 test images: 1.272\n","[7,   100] loss: 1.268 acc: 54.01 time: 5.54\n","[7,   200] loss: 1.273 acc: 53.97 time: 7.27\n","[7,   300] loss: 1.259 acc: 53.85 time: 6.11\n","TESTING:\n","Accuracy of the network on the 10000 test images: 54.89 %\n","Average loss on the 10000 test images: 1.256\n","[8,   100] loss: 1.237 acc: 55.33 time: 5.64\n","[8,   200] loss: 1.261 acc: 54.81 time: 6.49\n","[8,   300] loss: 1.266 acc: 54.36 time: 5.24\n","TESTING:\n","Accuracy of the network on the 10000 test images: 55.59 %\n","Average loss on the 10000 test images: 1.249\n","[9,   100] loss: 1.249 acc: 55.14 time: 5.53\n","[9,   200] loss: 1.231 acc: 55.28 time: 6.43\n","[9,   300] loss: 1.231 acc: 55.88 time: 5.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 55.49 %\n","Average loss on the 10000 test images: 1.242\n","[10,   100] loss: 1.226 acc: 55.51 time: 5.58\n","[10,   200] loss: 1.237 acc: 55.23 time: 6.48\n","[10,   300] loss: 1.227 acc: 55.71 time: 5.41\n","TESTING:\n","Accuracy of the network on the 10000 test images: 55.71 %\n","Average loss on the 10000 test images: 1.239\n","[11,   100] loss: 1.192 acc: 56.69 time: 6.29\n","[11,   200] loss: 1.166 acc: 58.39 time: 5.78\n","[11,   300] loss: 1.176 acc: 57.53 time: 5.95\n","TESTING:\n","Accuracy of the network on the 10000 test images: 57.73 %\n","Average loss on the 10000 test images: 1.188\n","[12,   100] loss: 1.168 acc: 57.77 time: 6.83\n","[12,   200] loss: 1.156 acc: 58.60 time: 5.36\n","[12,   300] loss: 1.160 acc: 58.22 time: 6.22\n","TESTING:\n","Accuracy of the network on the 10000 test images: 57.63 %\n","Average loss on the 10000 test images: 1.183\n","[13,   100] loss: 1.154 acc: 58.22 time: 6.54\n","[13,   200] loss: 1.176 acc: 57.53 time: 5.42\n","[13,   300] loss: 1.153 acc: 58.55 time: 6.50\n","TESTING:\n","Accuracy of the network on the 10000 test images: 57.72 %\n","Average loss on the 10000 test images: 1.179\n","[14,   100] loss: 1.148 acc: 58.28 time: 6.59\n","[14,   200] loss: 1.163 acc: 58.23 time: 5.65\n","[14,   300] loss: 1.152 acc: 57.95 time: 6.72\n","TESTING:\n","Accuracy of the network on the 10000 test images: 57.95 %\n","Average loss on the 10000 test images: 1.175\n","[15,   100] loss: 1.151 acc: 58.10 time: 6.65\n","[15,   200] loss: 1.154 acc: 58.09 time: 5.32\n","[15,   300] loss: 1.148 acc: 58.10 time: 6.63\n","TESTING:\n","Accuracy of the network on the 10000 test images: 58.08 %\n","Average loss on the 10000 test images: 1.170\n","[16,   100] loss: 1.140 acc: 58.70 time: 6.45\n","[16,   200] loss: 1.143 acc: 58.92 time: 5.37\n","[16,   300] loss: 1.144 acc: 58.85 time: 6.54\n","TESTING:\n","Accuracy of the network on the 10000 test images: 58.24 %\n","Average loss on the 10000 test images: 1.167\n","[17,   100] loss: 1.139 acc: 59.20 time: 5.86\n","[17,   200] loss: 1.148 acc: 58.19 time: 5.65\n","[17,   300] loss: 1.128 acc: 58.87 time: 6.16\n","TESTING:\n","Accuracy of the network on the 10000 test images: 58.11 %\n","Average loss on the 10000 test images: 1.168\n","[18,   100] loss: 1.132 acc: 59.12 time: 5.44\n","[18,   200] loss: 1.135 acc: 58.81 time: 5.83\n","[18,   300] loss: 1.141 acc: 58.54 time: 6.00\n","TESTING:\n","Accuracy of the network on the 10000 test images: 57.89 %\n","Average loss on the 10000 test images: 1.170\n","[19,   100] loss: 1.131 acc: 59.02 time: 5.54\n","[19,   200] loss: 1.152 acc: 58.50 time: 6.49\n","[19,   300] loss: 1.137 acc: 58.95 time: 5.46\n","TESTING:\n","Accuracy of the network on the 10000 test images: 57.98 %\n","Average loss on the 10000 test images: 1.164\n","[20,   100] loss: 1.112 acc: 59.77 time: 5.52\n","[20,   200] loss: 1.145 acc: 58.23 time: 6.54\n","[20,   300] loss: 1.128 acc: 59.26 time: 5.40\n","TESTING:\n","Accuracy of the network on the 10000 test images: 58.19 %\n","Average loss on the 10000 test images: 1.167\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"]},{"cell_type":"markdown","metadata":{"id":"ghPNhcJBrcNj"},"source":["## 2-2 Fine-tuning on the randomly initialized model (9 points) 46.29 %  跟前面得做比較 (正確) 10類\n","In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RfXAh9vxXRB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699626492983,"user_tz":-480,"elapsed":324,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"234d8a84-243c-46dc-b38b-1a0e9e03ee33"},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","#################################################\n","# TODO: Randomly initialize a ResNet18 model    #\n","#################################################\n","# Randomly initialize a ResNet18 model\n","\n","net = resnet18(pretrained=False,num_classes=10)\n","\n","print(net) # print your model and check the num_classes is correct\n","#################################################\n","#              End of your code                 #\n","#################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpx-SYAizt4p"},"outputs":[],"source":["#################################################################################################\n","# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n","# To do this, you should set requires_grad=False for the frozen layers.                         #\n","#################################################################################################\n","# Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable\n","for name, param in net.named_parameters():\n","    if \"layer4\" in name or \"fc\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","#################################################################################################\n","#                                          End of your code                                     #\n","#################################################################################################\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUFWizbHxgm2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699626500719,"user_tz":-480,"elapsed":3,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"7733c623-c502-4757-967c-5beeabc41bf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Params to learn:\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t fc.weight\n","\t fc.bias\n"]}],"source":["# Print all the trainable parameters\n","params_to_update = net.parameters()\n","print(\"Params to learn:\")\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxFrGj091AN_"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","# Note that your optimizer only needs to update the parameters that are trainable.\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(params_to_update, lr=0.1, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzRVy0MZxpoL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699627087259,"user_tz":-480,"elapsed":573568,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"6912a82f-2fcf-4661-a648-ad42695b44d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 2.256 acc: 25.05 time: 5.70\n","[1,   200] loss: 1.924 acc: 30.66 time: 6.84\n","[1,   300] loss: 1.863 acc: 32.68 time: 5.55\n","TESTING:\n","Accuracy of the network on the 10000 test images: 37.24 %\n","Average loss on the 10000 test images: 1.744\n","[2,   100] loss: 1.805 acc: 34.39 time: 5.98\n","[2,   200] loss: 1.779 acc: 35.72 time: 6.94\n","[2,   300] loss: 1.782 acc: 36.00 time: 5.86\n","TESTING:\n","Accuracy of the network on the 10000 test images: 38.92 %\n","Average loss on the 10000 test images: 1.698\n","[3,   100] loss: 1.744 acc: 36.75 time: 6.03\n","[3,   200] loss: 1.736 acc: 37.63 time: 6.54\n","[3,   300] loss: 1.740 acc: 36.99 time: 5.59\n","TESTING:\n","Accuracy of the network on the 10000 test images: 39.77 %\n","Average loss on the 10000 test images: 1.684\n","[4,   100] loss: 1.730 acc: 37.57 time: 6.93\n","[4,   200] loss: 1.705 acc: 38.31 time: 5.56\n","[4,   300] loss: 1.704 acc: 39.07 time: 6.75\n","TESTING:\n","Accuracy of the network on the 10000 test images: 40.59 %\n","Average loss on the 10000 test images: 1.654\n","[5,   100] loss: 1.694 acc: 38.84 time: 7.04\n","[5,   200] loss: 1.692 acc: 38.88 time: 5.78\n","[5,   300] loss: 1.691 acc: 38.74 time: 6.92\n","TESTING:\n","Accuracy of the network on the 10000 test images: 41.29 %\n","Average loss on the 10000 test images: 1.644\n","[6,   100] loss: 1.673 acc: 39.41 time: 6.72\n","[6,   200] loss: 1.691 acc: 39.79 time: 5.93\n","[6,   300] loss: 1.683 acc: 39.26 time: 6.64\n","TESTING:\n","Accuracy of the network on the 10000 test images: 41.73 %\n","Average loss on the 10000 test images: 1.633\n","[7,   100] loss: 1.673 acc: 39.21 time: 5.83\n","[7,   200] loss: 1.656 acc: 40.16 time: 6.93\n","[7,   300] loss: 1.666 acc: 39.64 time: 5.89\n","TESTING:\n","Accuracy of the network on the 10000 test images: 42.44 %\n","Average loss on the 10000 test images: 1.620\n","[8,   100] loss: 1.666 acc: 39.77 time: 6.78\n","[8,   200] loss: 1.646 acc: 41.55 time: 6.67\n","[8,   300] loss: 1.664 acc: 39.88 time: 5.66\n","TESTING:\n","Accuracy of the network on the 10000 test images: 41.87 %\n","Average loss on the 10000 test images: 1.632\n","[9,   100] loss: 1.654 acc: 40.12 time: 6.95\n","[9,   200] loss: 1.638 acc: 40.71 time: 5.71\n","[9,   300] loss: 1.653 acc: 41.06 time: 6.87\n","TESTING:\n","Accuracy of the network on the 10000 test images: 43.57 %\n","Average loss on the 10000 test images: 1.607\n","[10,   100] loss: 1.651 acc: 40.37 time: 7.04\n","[10,   200] loss: 1.646 acc: 40.74 time: 5.78\n","[10,   300] loss: 1.628 acc: 41.04 time: 6.77\n","TESTING:\n","Accuracy of the network on the 10000 test images: 42.58 %\n","Average loss on the 10000 test images: 1.598\n","[11,   100] loss: 1.619 acc: 41.81 time: 8.22\n","[11,   200] loss: 1.588 acc: 43.08 time: 8.26\n","[11,   300] loss: 1.583 acc: 42.93 time: 6.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 44.60 %\n","Average loss on the 10000 test images: 1.563\n","[12,   100] loss: 1.584 acc: 43.59 time: 6.46\n","[12,   200] loss: 1.586 acc: 42.88 time: 6.40\n","[12,   300] loss: 1.579 acc: 43.29 time: 6.47\n","TESTING:\n","Accuracy of the network on the 10000 test images: 44.57 %\n","Average loss on the 10000 test images: 1.552\n","[13,   100] loss: 1.566 acc: 44.09 time: 7.74\n","[13,   200] loss: 1.564 acc: 43.95 time: 5.71\n","[13,   300] loss: 1.578 acc: 42.97 time: 6.95\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.18 %\n","Average loss on the 10000 test images: 1.548\n","[14,   100] loss: 1.559 acc: 44.23 time: 5.85\n","[14,   200] loss: 1.553 acc: 44.38 time: 6.97\n","[14,   300] loss: 1.563 acc: 43.90 time: 5.78\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.17 %\n","Average loss on the 10000 test images: 1.545\n","[15,   100] loss: 1.549 acc: 44.66 time: 5.89\n","[15,   200] loss: 1.562 acc: 44.09 time: 6.92\n","[15,   300] loss: 1.563 acc: 44.25 time: 5.95\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.49 %\n","Average loss on the 10000 test images: 1.542\n","[16,   100] loss: 1.558 acc: 44.32 time: 7.10\n","[16,   200] loss: 1.549 acc: 44.31 time: 5.74\n","[16,   300] loss: 1.553 acc: 44.81 time: 6.87\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.70 %\n","Average loss on the 10000 test images: 1.538\n","[17,   100] loss: 1.539 acc: 45.04 time: 7.05\n","[17,   200] loss: 1.541 acc: 44.58 time: 5.73\n","[17,   300] loss: 1.552 acc: 43.84 time: 6.71\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.33 %\n","Average loss on the 10000 test images: 1.540\n","[18,   100] loss: 1.528 acc: 45.44 time: 6.30\n","[18,   200] loss: 1.548 acc: 44.32 time: 6.10\n","[18,   300] loss: 1.557 acc: 44.34 time: 7.84\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.80 %\n","Average loss on the 10000 test images: 1.537\n","[19,   100] loss: 1.544 acc: 44.78 time: 5.93\n","[19,   200] loss: 1.533 acc: 45.43 time: 6.81\n","[19,   300] loss: 1.531 acc: 45.28 time: 5.63\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.61 %\n","Average loss on the 10000 test images: 1.534\n","[20,   100] loss: 1.534 acc: 45.19 time: 6.41\n","[20,   200] loss: 1.539 acc: 44.93 time: 6.41\n","[20,   300] loss: 1.539 acc: 44.64 time: 6.22\n","TESTING:\n","Accuracy of the network on the 10000 test images: 46.29 %\n","Average loss on the 10000 test images: 1.528\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"]},{"cell_type":"markdown","metadata":{"id":"WcN54tcNN15U"},"source":["## 3-1 Supervised training on the pre-trained model (9 points) 87 % 讀黨 直接train 10類\n","In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n","\n","**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xR9h_S1N6Xi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699630189553,"user_tz":-480,"elapsed":299,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"0f9aabac-570e-45c9-84c2-a601c2d01fd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Model:\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=4, bias=True)\n",")\n","\n","Modified Model:\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","#####################################################\n","#     TODO: Load the pre-trained ResNet18 model     #\n","#####################################################\n","\n","net = resnet18(pretrained=False,num_classes=4)\n","\n","# 載入模型權重\n","net.load_state_dict(torch.load('rotation_model.pt', map_location='cpu'))\n","\n","# 印修改前的模型\n","print(\"Original Model:\")\n","print(net)\n","\n","# 原始fc層修改\n","fc_layers = [nn.Linear(512, 10)]\n","\n","# 新fc層替換原始fc\n","net.fc = nn.Sequential(*fc_layers)\n","\n","# 印修改後的模型\n","print(\"\\nModified Model:\")\n","print(net) # print your model and check the num_classes is correct\n","#####################################################\n","#                End of your code                   #\n","#####################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGozc2cM0ADw"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.1, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGWW7gzCz_Bu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699630812395,"user_tz":-480,"elapsed":618586,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"467b5de9-b31a-4e27-b125-39a777197057"},"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","    Traceback (most recent call last):\n","assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","    AssertionError: self._shutdown_workers()can only test a child process\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 1.481 acc: 45.12 time: 7.07\n","[1,   200] loss: 1.185 acc: 57.73 time: 7.43\n","[1,   300] loss: 1.103 acc: 61.07 time: 6.50\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20><function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","        self._shutdown_workers()\n","self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    \n","if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    \n","if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","AssertionErrorAssertionError: : can only test a child process\n","can only test a child processException ignored in: \n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Exception ignored in: Traceback (most recent call last):\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","    Traceback (most recent call last):\n","self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    AssertionError: if w.is_alive():\n","can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 65.60 %\n","Average loss on the 10000 test images: 0.995\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    if w.is_alive():\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    AssertionError: if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child processcan only test a child process\n","\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","Traceback (most recent call last):\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","self._shutdown_workers()    \n","if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","assert self._parent_pid == os.getpid(), 'can only test a child process'    \n","AssertionErrorAssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",": : can only test a child processcan only test a child process\n","\n"]},{"output_type":"stream","name":"stdout","text":["[2,   100] loss: 0.961 acc: 65.96 time: 7.91\n","[2,   200] loss: 0.941 acc: 67.20 time: 6.06\n","[2,   300] loss: 0.911 acc: 68.36 time: 7.11\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionErrorException ignored in: : can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","AssertionError    : can only test a child processself._shutdown_workers()\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 70.91 %\n","Average loss on the 10000 test images: 0.856\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[3,   100] loss: 0.839 acc: 70.35 time: 7.01\n","[3,   200] loss: 0.822 acc: 70.94 time: 7.48\n","[3,   300] loss: 0.812 acc: 71.64 time: 6.21\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    \n","    self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","Traceback (most recent call last):\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    if w.is_alive():\n","self._shutdown_workers()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError\n",": Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>can only test a child process\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 72.50 %\n","Average loss on the 10000 test images: 0.806\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>Exception ignored in: \n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>Traceback (most recent call last):\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","self._shutdown_workers()    \n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","if w.is_alive():    \n","if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError:     can only test a child process\n","assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n","AssertionError: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>can only test a child process\n","\n","Traceback (most recent call last):\n","Exception ignored in:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>    \n","self._shutdown_workers()\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    self._shutdown_workers()\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","if w.is_alive():    \n","if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[4,   100] loss: 0.762 acc: 73.60 time: 7.82\n","[4,   200] loss: 0.747 acc: 73.90 time: 6.14\n","[4,   300] loss: 0.741 acc: 74.38 time: 7.00\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","self._shutdown_workers()Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","        if w.is_alive():self._shutdown_workers()\n","\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: \n","can only test a child process\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>    \n","Traceback (most recent call last):\n","assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",":     can only test a child processself._shutdown_workers()\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","Exception ignored in:     if w.is_alive():\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",": can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 74.82 %\n","Average loss on the 10000 test images: 0.741\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>Exception ignored in: \n","    Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","self._shutdown_workers()    self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","if w.is_alive():      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","Traceback (most recent call last):\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","if w.is_alive():    \n","self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","assert self._parent_pid == os.getpid(), 'can only test a child process'    \n","AssertionErrorif w.is_alive():: \n","can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>AssertionError\n",": Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[5,   100] loss: 0.689 acc: 76.20 time: 6.75\n","[5,   200] loss: 0.710 acc: 75.56 time: 7.32\n","[5,   300] loss: 0.698 acc: 75.67 time: 6.11\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","    Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    \n","if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","if w.is_alive():    \n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","assert self._parent_pid == os.getpid(), 'can only test a child process'    \n","AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n",": \n","Traceback (most recent call last):\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","Exception ignored in: self._shutdown_workers()    \n","can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n","if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 75.68 %\n","Average loss on the 10000 test images: 0.715\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","    Traceback (most recent call last):\n","self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","self._shutdown_workers()\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","if w.is_alive():    if w.is_alive():\n","\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>can only test a child process\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    Exception ignored in: self._shutdown_workers()\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","    Traceback (most recent call last):\n","if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    self._shutdown_workers()\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","    AssertionErrorif w.is_alive():: \n","can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[6,   100] loss: 0.647 acc: 77.47 time: 8.16\n","[6,   200] loss: 0.655 acc: 77.04 time: 6.44\n","[6,   300] loss: 0.668 acc: 77.19 time: 7.45\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>    self._shutdown_workers()\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","Traceback (most recent call last):\n","    if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: : can only test a child processcan only test a child process\n","\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Exception ignored in: Traceback (most recent call last):\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    \n","self._shutdown_workers()Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","        assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: self._shutdown_workers()can only test a child process\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 76.53 %\n","Average loss on the 10000 test images: 0.702\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>Exception ignored in: \n","Traceback (most recent call last):\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","Traceback (most recent call last):\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n","AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n","can only test a child processAssertionError\n",": Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","can only test a child process  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    \n","if w.is_alive():\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    if w.is_alive():    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","AssertionError    : assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n","\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[7,   100] loss: 0.630 acc: 78.10 time: 7.12\n","[7,   200] loss: 0.635 acc: 78.23 time: 7.29\n","[7,   300] loss: 0.607 acc: 78.86 time: 6.13\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>    \n","if w.is_alive():Traceback (most recent call last):\n","\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n","AssertionErrorself._shutdown_workers()\n",":   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","can only test a child process\n","    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","if w.is_alive():    \n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","self._shutdown_workers()    \n","assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",":     if w.is_alive():can only test a child process\n","\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","Traceback (most recent call last):\n","AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",":     can only test a child processself._shutdown_workers()\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 77.15 %\n","Average loss on the 10000 test images: 0.683\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","        self._shutdown_workers()if w.is_alive():\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n","\n","AssertionError: can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","AssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    Traceback (most recent call last):\n","self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","\n","    self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    \n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():if w.is_alive():\n","\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError\n",": AssertionErrorcan only test a child process\n",": can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[8,   100] loss: 0.582 acc: 80.07 time: 7.89\n","[8,   200] loss: 0.602 acc: 79.18 time: 6.29\n","[8,   300] loss: 0.603 acc: 79.42 time: 7.43\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    Exception ignored in: if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: \n","can only test a child processException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","\n","self._shutdown_workers()Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n","\n","AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",":     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","AssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>can only test a child process\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 77.46 %\n","Average loss on the 10000 test images: 0.671\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    Exception ignored in: if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    can only test a child processself._shutdown_workers()\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b0c4f756c20>self._shutdown_workers()\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","        if w.is_alive():\n","self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n","        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",":     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n","\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[9,   100] loss: 0.562 acc: 80.76 time: 7.81\n","[9,   200] loss: 0.581 acc: 79.74 time: 7.56\n","[9,   300] loss: 0.573 acc: 80.41 time: 6.24\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.63 %\n","Average loss on the 10000 test images: 0.645\n","[10,   100] loss: 0.535 acc: 81.48 time: 6.58\n","[10,   200] loss: 0.561 acc: 80.73 time: 6.90\n","[10,   300] loss: 0.545 acc: 81.35 time: 8.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.55 %\n","Average loss on the 10000 test images: 0.631\n","[11,   100] loss: 0.477 acc: 83.93 time: 7.64\n","[11,   200] loss: 0.444 acc: 84.84 time: 6.29\n","[11,   300] loss: 0.421 acc: 85.55 time: 7.39\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.10 %\n","Average loss on the 10000 test images: 0.568\n","[12,   100] loss: 0.432 acc: 84.95 time: 6.53\n","[12,   200] loss: 0.419 acc: 85.58 time: 7.26\n","[12,   300] loss: 0.416 acc: 85.59 time: 6.40\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.33 %\n","Average loss on the 10000 test images: 0.565\n","[13,   100] loss: 0.399 acc: 86.05 time: 7.80\n","[13,   200] loss: 0.401 acc: 86.07 time: 6.11\n","[13,   300] loss: 0.410 acc: 85.73 time: 7.13\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.22 %\n","Average loss on the 10000 test images: 0.563\n","[14,   100] loss: 0.406 acc: 85.74 time: 6.99\n","[14,   200] loss: 0.395 acc: 86.12 time: 7.04\n","[14,   300] loss: 0.395 acc: 86.30 time: 6.37\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.78 %\n","Average loss on the 10000 test images: 0.561\n","[15,   100] loss: 0.367 acc: 87.44 time: 6.49\n","[15,   200] loss: 0.382 acc: 86.67 time: 7.38\n","[15,   300] loss: 0.388 acc: 86.31 time: 6.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.76 %\n","Average loss on the 10000 test images: 0.562\n","[16,   100] loss: 0.361 acc: 87.46 time: 7.45\n","[16,   200] loss: 0.389 acc: 86.35 time: 6.38\n","[16,   300] loss: 0.382 acc: 86.56 time: 7.44\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.72 %\n","Average loss on the 10000 test images: 0.561\n","[17,   100] loss: 0.373 acc: 87.37 time: 6.59\n","[17,   200] loss: 0.359 acc: 87.45 time: 7.39\n","[17,   300] loss: 0.373 acc: 87.02 time: 6.24\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.65 %\n","Average loss on the 10000 test images: 0.561\n","[18,   100] loss: 0.366 acc: 87.16 time: 7.41\n","[18,   200] loss: 0.362 acc: 87.32 time: 6.49\n","[18,   300] loss: 0.374 acc: 86.97 time: 7.45\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.47 %\n","Average loss on the 10000 test images: 0.569\n","[19,   100] loss: 0.370 acc: 87.40 time: 7.70\n","[19,   200] loss: 0.358 acc: 87.41 time: 7.05\n","[19,   300] loss: 0.350 acc: 88.03 time: 6.66\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.39 %\n","Average loss on the 10000 test images: 0.568\n","[20,   100] loss: 0.353 acc: 87.68 time: 6.41\n","[20,   200] loss: 0.362 acc: 87.24 time: 7.29\n","[20,   300] loss: 0.345 acc: 87.80 time: 6.44\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.72 %\n","Average loss on the 10000 test images: 0.564\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"]},{"cell_type":"markdown","metadata":{"id":"xjVTp9jhefTi"},"source":["## 3-2 Supervised training on the randomly initialized model (9 points) 80.50 % 不讀檔  10類 不false\n","In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEjy8TBieeLK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699627926933,"user_tz":-480,"elapsed":303,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}},"outputId":"8765ad20-92bd-4c38-97b9-6ca9dc71cf16"},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","#################################################\n","# TODO: Randomly initialize a ResNet18 model    #\n","#################################################\n","\n","# Randomly initialize a ResNet18 model\n","net = resnet18(pretrained=False,num_classes=10)\n","\n","print(net) # print your model and check the num_classes is correct\n","#################################################\n","#              End of your code                 #\n","#################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEY90pK_0ZAm"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMDwelhY0auO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b4fdf82-bc00-44d9-c7e1-8f40607f4498","executionInfo":{"status":"ok","timestamp":1699628525668,"user_tz":-480,"elapsed":594217,"user":{"displayName":"游凱翔","userId":"07457406092668720636"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 2.253 acc: 23.69 time: 7.36\n","[1,   200] loss: 1.887 acc: 32.40 time: 5.87\n","[1,   300] loss: 1.739 acc: 36.23 time: 7.07\n","TESTING:\n","Accuracy of the network on the 10000 test images: 43.59 %\n","Average loss on the 10000 test images: 1.546\n","[2,   100] loss: 1.544 acc: 43.48 time: 6.02\n","[2,   200] loss: 1.463 acc: 47.09 time: 6.97\n","[2,   300] loss: 1.384 acc: 50.22 time: 5.99\n","TESTING:\n","Accuracy of the network on the 10000 test images: 52.87 %\n","Average loss on the 10000 test images: 1.303\n","[3,   100] loss: 1.283 acc: 53.30 time: 6.31\n","[3,   200] loss: 1.239 acc: 55.50 time: 7.30\n","[3,   300] loss: 1.199 acc: 57.23 time: 6.39\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.42 %\n","Average loss on the 10000 test images: 1.104\n","[4,   100] loss: 1.125 acc: 59.14 time: 7.39\n","[4,   200] loss: 1.093 acc: 60.91 time: 5.89\n","[4,   300] loss: 1.087 acc: 61.42 time: 6.99\n","TESTING:\n","Accuracy of the network on the 10000 test images: 65.50 %\n","Average loss on the 10000 test images: 0.983\n","[5,   100] loss: 1.004 acc: 63.94 time: 6.70\n","[5,   200] loss: 0.996 acc: 64.35 time: 7.22\n","[5,   300] loss: 0.955 acc: 65.74 time: 6.19\n","TESTING:\n","Accuracy of the network on the 10000 test images: 68.22 %\n","Average loss on the 10000 test images: 0.908\n","[6,   100] loss: 0.920 acc: 67.55 time: 6.35\n","[6,   200] loss: 0.915 acc: 67.52 time: 7.24\n","[6,   300] loss: 0.897 acc: 68.45 time: 5.98\n","TESTING:\n","Accuracy of the network on the 10000 test images: 69.30 %\n","Average loss on the 10000 test images: 0.889\n","[7,   100] loss: 0.862 acc: 69.49 time: 7.08\n","[7,   200] loss: 0.835 acc: 70.96 time: 6.14\n","[7,   300] loss: 0.828 acc: 70.81 time: 7.03\n","TESTING:\n","Accuracy of the network on the 10000 test images: 71.88 %\n","Average loss on the 10000 test images: 0.824\n","[8,   100] loss: 0.788 acc: 71.88 time: 7.37\n","[8,   200] loss: 0.791 acc: 72.73 time: 6.32\n","[8,   300] loss: 0.784 acc: 72.69 time: 6.82\n","TESTING:\n","Accuracy of the network on the 10000 test images: 72.56 %\n","Average loss on the 10000 test images: 0.785\n","[9,   100] loss: 0.745 acc: 74.37 time: 6.21\n","[9,   200] loss: 0.739 acc: 74.14 time: 7.31\n","[9,   300] loss: 0.750 acc: 73.70 time: 6.05\n","TESTING:\n","Accuracy of the network on the 10000 test images: 73.39 %\n","Average loss on the 10000 test images: 0.771\n","[10,   100] loss: 0.707 acc: 75.12 time: 7.54\n","[10,   200] loss: 0.702 acc: 75.43 time: 6.16\n","[10,   300] loss: 0.704 acc: 75.75 time: 7.24\n","TESTING:\n","Accuracy of the network on the 10000 test images: 74.36 %\n","Average loss on the 10000 test images: 0.743\n","[11,   100] loss: 0.616 acc: 78.80 time: 7.05\n","[11,   200] loss: 0.584 acc: 79.74 time: 7.09\n","[11,   300] loss: 0.551 acc: 80.57 time: 6.54\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.09 %\n","Average loss on the 10000 test images: 0.637\n","[12,   100] loss: 0.536 acc: 81.38 time: 6.37\n","[12,   200] loss: 0.534 acc: 81.53 time: 7.41\n","[12,   300] loss: 0.547 acc: 80.90 time: 6.16\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.75 %\n","Average loss on the 10000 test images: 0.623\n","[13,   100] loss: 0.516 acc: 81.98 time: 7.48\n","[13,   200] loss: 0.523 acc: 81.68 time: 6.24\n","[13,   300] loss: 0.524 acc: 82.01 time: 7.25\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.86 %\n","Average loss on the 10000 test images: 0.619\n","[14,   100] loss: 0.497 acc: 82.56 time: 7.09\n","[14,   200] loss: 0.496 acc: 82.76 time: 7.05\n","[14,   300] loss: 0.522 acc: 81.95 time: 6.40\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.01 %\n","Average loss on the 10000 test images: 0.618\n","[15,   100] loss: 0.489 acc: 82.77 time: 6.20\n","[15,   200] loss: 0.500 acc: 82.73 time: 7.27\n","[15,   300] loss: 0.487 acc: 83.22 time: 6.07\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.48 %\n","Average loss on the 10000 test images: 0.608\n","[16,   100] loss: 0.495 acc: 82.62 time: 7.41\n","[16,   200] loss: 0.488 acc: 82.80 time: 6.14\n","[16,   300] loss: 0.476 acc: 83.58 time: 7.00\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.27 %\n","Average loss on the 10000 test images: 0.617\n","[17,   100] loss: 0.458 acc: 83.96 time: 7.13\n","[17,   200] loss: 0.482 acc: 83.34 time: 5.79\n","[17,   300] loss: 0.479 acc: 83.45 time: 7.09\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.64 %\n","Average loss on the 10000 test images: 0.608\n","[18,   100] loss: 0.452 acc: 84.39 time: 6.25\n","[18,   200] loss: 0.456 acc: 83.72 time: 7.18\n","[18,   300] loss: 0.479 acc: 83.12 time: 6.07\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.94 %\n","Average loss on the 10000 test images: 0.601\n","[19,   100] loss: 0.446 acc: 84.70 time: 6.77\n","[19,   200] loss: 0.457 acc: 84.30 time: 6.47\n","[19,   300] loss: 0.445 acc: 84.19 time: 6.64\n","TESTING:\n","Accuracy of the network on the 10000 test images: 80.02 %\n","Average loss on the 10000 test images: 0.603\n","[20,   100] loss: 0.428 acc: 85.08 time: 7.36\n","[20,   200] loss: 0.444 acc: 84.23 time: 6.06\n","[20,   300] loss: 0.430 acc: 84.80 time: 7.22\n","TESTING:\n","Accuracy of the network on the 10000 test images: 80.13 %\n","Average loss on the 10000 test images: 0.599\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"]},{"cell_type":"markdown","metadata":{"id":"fqkBB-iOta4a"},"source":["# Write report (37 points)\n","\n","本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫請大家根據以下要求完成，就請大家將嘗試的結果寫在report裡，祝大家順利！\n","\n","1. (13 points) Train a ResNet18 on the Rotation task and report the test performance. Discuss why such a task helps in learning features that are generalizable to other visual tasks.\n","\n","2. (12 points) Initializing from the Rotation model or from random weights, fine-tune only the weights of the final block of convolutional layers and linear layer on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights. You can also discuss how the performance of pre-trained models affects downstream tasks, the performance of fine-tuning different numbers of layers, and so on.\n","\n","3. (12 points) Initializing from the Rotation model or from random weights, train the full network on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights."]},{"cell_type":"markdown","source":["（13分）在旋轉任務上訓練一個ResNet18並報告測試性能。討論為什麼這樣的任務有助於學習對其他視覺任務具有泛化能力的特徵。\n","\n","（12分）從旋轉模型或隨機權重初始化，僅微調最後一個卷積層塊和線性層的權重，在監督式CIFAR10分類任務中報告測試結果並比較這兩種模型的性能。提供您的觀察和見解。您還可以討論預訓練模型的性能如何影響下游任務、微調不同數量層次的性能等。\n","\n","（12分）從旋轉模型或隨機權重初始化，將完整網絡用於監督式CIFAR10分類任務上進行訓練。報告測試結果並比較這兩種模型的性能。提供您的觀察和見解。"],"metadata":{"id":"zFpRaJA5esqq"}},{"cell_type":"markdown","metadata":{"id":"Ihd3cRHUta4b"},"source":["# Extra Credit (13 points)\n","\n","上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n","\n","- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n","- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n","  \n","- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"]},{"cell_type":"markdown","metadata":{"id":"ucLd2qk5ta4b"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4","timestamp":1677623843954}],"collapsed_sections":["WcN54tcNN15U"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"}}},"nbformat":4,"nbformat_minor":0}